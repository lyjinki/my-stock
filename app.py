import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

# 1. ë„¤ì´ë²„ ì¦ê¶Œ ë°ì´í„° í¬ë¡¤ë§ í•¨ìˆ˜
def get_naver_stock_data():
    url = "https://finance.naver.com/sise/sise_quant.naver"
    headers = {'User-Agent': 'Mozilla/5.0'}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')
    
    table = soup.select_one('table.type_2')
    df = pd.read_html(str(table))[0]
    
    # ë¹ˆ ì¤„ ì‚­ì œ
    df = df.dropna(subset=['ì¢…ëª©ëª…'])

    # ìˆ«ì ë°ì´í„° ì •ë¦¬ (ì†Œìˆ«ì  ì œê±° ë° ì •ìˆ˜ ë³€í™˜)
    for col in ['í˜„ì¬ê°€', 'ê±°ë˜ëŸ‰']:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
    
    # ë²ˆí˜¸ ì¬ì •ë ¬
    df = df.reset_index(drop=True)
    df.index = df.index + 1
    
    return df[['ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'ì „ì¼ë¹„', 'ë“±ë½ë¥ ', 'ê±°ë˜ëŸ‰']]

# 2. ìƒìŠ¹/í•˜ë½ ìƒ‰ìƒ ì…íˆëŠ” í•¨ìˆ˜
def color_variation(val):
    if '+' in str(val):
        return 'color: #ff4b4b' # ì ìƒ‰
    elif '-' in str(val):
        return 'color: #3133ff' # ì²­ìƒ‰
    return ''

# 3. Streamlit UI ì„¤ì •
st.set_page_config(page_title="KOSPI ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")

st.title("ğŸ“ˆ KOSPI ì‹¤ì‹œê°„ íˆ¬ì ë¶„ì„")
st.markdown(f"**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸:** {time.strftime('%Y-%m-%d %H:%M:%S')}")

# ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
if st.button('ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨'):
    st.rerun()

# ë°ì´í„° ë¯¸ë¦¬ ê°€ì ¸ì˜¤ê¸°
data = get_naver_stock_data()

# 4. ë ˆì´ì•„ì›ƒ êµ¬ì„±
col1, col2 = st.columns(2)

with col1:
    st.subheader("ğŸ”¥ í˜„ì¬ ê±°ë˜ìƒìœ„ (TOP 10)")
    # ìƒë‹¨ í‘œì—ë„ ì½¤ë§ˆ, ì›, ì£¼, ìƒ‰ìƒ ì ìš©
    st.dataframe(
        data.head(10).style.format({
            'í˜„ì¬ê°€': '{:,}ì›', 
            'ê±°ë˜ëŸ‰': '{:,}ì£¼'
        }).map(color_variation, subset=['ì „ì¼ë¹„', 'ë“±ë½ë¥ ']),
        use_container_width=True
    )

with col2:
# 1. KOSPI ìƒìŠ¹ë¥  ìƒìœ„ ê¸°ì—… ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë³„ë„ì˜ ë¡œì§
    def get_top_rising_companies():
        url = "https://finance.naver.com/sise/sise_high_up.naver?sosok=0" # KOSPI(0) ìƒìŠ¹ë¥  ìƒìœ„
        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ìƒìŠ¹ë¥  ìƒìœ„ í…Œì´ë¸” ì¶”ì¶œ
        table = soup.select_one('table.type_2')
        df = pd.read_html(str(table))[0]
        
        # ë¹ˆ ì¤„ ë° ë¶ˆí•„ìš”í•œ í–‰ ì œê±°
        df = df.dropna(subset=['ì¢…ëª©ëª…']).head(10)
        
        # ë“±ë½ë¥ ì—ì„œ %ì™€ + ì œê±° í›„ ìˆ«ìë¡œ ë³€í™˜
        df['ë“±ë½ë¥ _ìˆ«ì'] = df['ë“±ë½ë¥ '].str.replace('%','').str.replace('+','', regex=False).astype(float)
        return df

    # ë°ì´í„° í˜¸ì¶œ
    try:
        top_rising_df = get_top_rising_companies()
        
        # 2. ì°¨íŠ¸ ê·¸ë¦¬ê¸° (ë§‰ëŒ€ ê·¸ë˜í”„)
        st.bar_chart(top_rising_df.set_index('ì¢…ëª©ëª…')['ë“±ë½ë¥ _ìˆ«ì'], color="#ff4b4b")
        
        # 3. 1ìœ„ ê¸°ì—… ê°•ì¡°
        top_company = top_rising_df.iloc[0]['ì¢…ëª©ëª…']
        top_percent = top_rising_df.iloc[0]['ë“±ë½ë¥ ']
        st.success(f"í˜„ì¬ KOSPIì—ì„œ **{top_company}** ê¸°ì—…ì´ **{top_percent}**ë¡œ ê°€ì¥ ë†’ê²Œ ìƒìŠ¹í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        st.error("ìƒìŠ¹ë¥  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
# í•˜ë‹¨ ìƒì„¸ í…Œì´ë¸”
st.divider()
st.subheader("ğŸ“Š ì „ì²´ ì¢…ëª© ìƒì„¸ ë³´ê¸°")
st.dataframe(
    data.style.format({
        'í˜„ì¬ê°€': '{:,}ì›', 
        'ê±°ë˜ëŸ‰': '{:,}ì£¼'
    }).map(color_variation, subset=['ì „ì¼ë¹„', 'ë“±ë½ë¥ ']),
    use_container_width=True
)
# 5. KOSPI ì‹œê°€ì´ì•¡ ìƒìœ„ 20ìœ„ ê¸°ì—… ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_kospi_top_20():
    # ë„¤ì´ë²„ ì¦ê¶Œ ì‹œê°€ì´ì•¡ í˜ì´ì§€ (KOSPI)
    url = "https://finance.naver.com/sise/sise_market_sum.naver?&page=1"
    headers = {'User-Agent': 'Mozilla/5.0'}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')
    
    table = soup.select_one('table.type_2')
    df = pd.read_html(str(table))[0]
    
    # ë¶ˆí•„ìš”í•œ í–‰(êµ¬ë¶„ì„  ë“±) ì œê±° ë° ìƒìœ„ 20ê°œ ì¶”ì¶œ
    df = df.dropna(subset=['ì¢…ëª©ëª…']).head(20)
    
    # ìˆ«ì ë°ì´í„° ì •ë¦¬
    for col in ['í˜„ì¬ê°€', 'ì‹œê°€ì´ì•¡']:
        # ì‹œê°€ì´ì•¡ì€ ë‹¨ìœ„ê°€ ì»¤ì„œ ìˆ«ìë¡œë§Œ ë³€í™˜
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
    
    # ë²ˆí˜¸ ì¬ì •ë ¬
    df = df.reset_index(drop=True)
    df.index = df.index + 1
    
    # í•„ìš”í•œ ì—´ë§Œ ì„ íƒ (ê±°ë˜ëŸ‰ ëŒ€ì‹  ì‹œê°€ì´ì•¡ í¬í•¨ ê°€ëŠ¥)
    return df[['ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'ì „ì¼ë¹„', 'ë“±ë½ë¥ ', 'ì‹œê°€ì´ì•¡']]

# 6. KOSPI ìƒìœ„ 20ìœ„ ì„¹ì…˜ UI ì¶œë ¥
st.divider()
st.subheader("ğŸ† KOSPI ì‹œê°€ì´ì•¡ ìƒìœ„ 20ìœ„ ê¸°ì—… ìƒí™©")

with st.spinner('ìƒìœ„ 20ìœ„ ê¸°ì—… ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...'):
    top_20_data = get_kospi_top_20()
    
    st.dataframe(
        top_20_data.style.format({
            'í˜„ì¬ê°€': '{:,}ì›',
            'ì‹œê°€ì´ì•¡': '{:,}ì–µ'
        }).map(color_variation, subset=['ì „ì¼ë¹„', 'ë“±ë½ë¥ ']),
        use_container_width=True
    )

st.caption("â€» ì‹œê°€ì´ì•¡ ë°ì´í„°ëŠ” ë„¤ì´ë²„ ì¦ê¶Œ ê¸°ì¤€ì´ë©° ì‹¤ì‹œê°„ ìƒí™©ì— ë”°ë¼ ë³€ë™ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

import datetime

# 7. ìµœì‹  ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜ (ì‹œì´ ìƒìœ„ ê¸°ì—… ìœ„ì£¼)
def get_stock_news():
    # ë„¤ì´ë²„ ì¦ê¶Œ ì£¼ìš” ë‰´ìŠ¤ í˜ì´ì§€ (KOSPI/ì½”ìŠ¤ë‹¥ ì¢…í•© ë‰´ìŠ¤)
    url = "https://finance.naver.com/news/mainnews.naver"
    headers = {'User-Agent': 'Mozilla/5.0'}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')
    
    news_list = []
    today = datetime.datetime.now()
    
    # ë‰´ìŠ¤ í•­ëª© ì¶”ì¶œ
    items = soup.select('.mainNewsList .articleItem')
    for item in items:
        title_tag = item.select_one('.articleSubject a')
        if title_tag:
            title = title_tag.get_text(strip=True)
            link = "https://finance.naver.com" + title_tag['href']
            
            # ë‚ ì§œ í™•ì¸ (ê°„ì´ í•„í„°ë§: ì‹¤ì œ ìš´ì˜ì‹œëŠ” ìƒì„¸ í˜ì´ì§€ ë‚ ì§œ í™•ì¸ í•„ìš”)
            # ì—¬ê¸°ì„œëŠ” ëª©ë¡ì— ìˆëŠ” ë‰´ìŠ¤ë“¤ì„ 3ì¼ ì´ë‚´ë¡œ ê°„ì£¼í•˜ê±°ë‚˜ ìµœì‹ ìˆœìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
            news_list.append({"ì œëª©": title, "ë§í¬": link})
            
    return pd.DataFrame(news_list)

# 8. ë‰´ìŠ¤ ì„¹ì…˜ UI ë° í˜ì´ì§€ë„¤ì´ì…˜
st.divider()
st.subheader("ğŸ“° KOSPI ì£¼ìš” ì¢…ëª© ìµœì‹  ë‰´ìŠ¤ (3ì¼ ì´ë‚´)")

# ë‰´ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
news_df = get_stock_news()

if not news_df.empty:
    # í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬ (ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì‚¬ìš©)
    if 'news_page' not in st.session_state:
        st.session_state.news_page = 0

    items_per_page = 10
    total_pages = (len(news_df) // items_per_page) + 1
    
    start_idx = st.session_state.news_page * items_per_page
    end_idx = start_idx + items_per_page
    
    # í˜„ì¬ í˜ì´ì§€ ë‰´ìŠ¤ í‘œì‹œ
    current_news = news_df.iloc[start_idx:end_idx]
    
    for idx, row in current_news.iterrows():
        st.markdown(f"â€¢ [{row['ì œëª©']}]({row['ë§í¬']})")
    
    # í˜ì´ì§€ ì´ë™ ë²„íŠ¼
    col_prev, col_page, col_next = st.columns([1, 2, 1])
    
    with col_prev:
        if st.button("ì´ì „ ë‰´ìŠ¤") and st.session_state.news_page > 0:
            st.session_state.news_page -= 1
            st.rerun()
            
    with col_page:
        st.write(f"í˜ì´ì§€ {st.session_state.news_page + 1} / {total_pages}")
        
    with col_next:
        if st.button("ë‹¤ìŒ ë‰´ìŠ¤") and st.session_state.news_page < total_pages - 1:
            st.session_state.news_page += 1
            st.rerun()
else:
    st.write("ìµœê·¼ 3ì¼ ì´ë‚´ì˜ ì£¼ìš” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")